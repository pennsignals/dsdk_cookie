{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e5907a0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. Jupyterlab\n",
    "\n",
    "## 1.1. Setup\n",
    "\n",
    "1. Choose the `Python [conda env:.venv]` from the menu in the top right corner of this page.\n",
    "\n",
    "2. The `dsdk` and `cfgenvy` modules are already installed into the conda venv, along with any dependencies added to requirement.txt SO LONG AS jupyterlab has been started with `docker-compose up --build jupyterlab &`. The docker container image build for jupyterlab will cache build steps applying `./jupyterlab/environment.yaml` with from modules anaconda and conda forge, and will apply `./requirements.txt` last with modules from pypi, or specifically pulled from public git repositories --this is a way to install your own data science helper modules like dsdk--. Only the first run of the jupyterlab container image build will be slow so long as environment.yaml is not changed.\n",
    "\n",
    "2. If there is a predict python module developed with this project, it may also be installed into the conda env, but this step is optional and may not be useful: --see setup.py--:\n",
    "\n",
    "    a. Production vs development mode: `pip install ...` vs. `pip install -e ...`. Development mode builds symlinks between site-packages and the code in src. Reinstall is not required after changes, but there other are limitations.\n",
    "\n",
    "    b. Sparce vs with additional dependencies: `pip install .` vs. `pip install .[all]`. Additional dependencies include lint and test tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41a16d9e-1743-48fa-a2a6-fe5b6bbec788",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b225ea69-c7ce-4818-a709-759332937b8d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///tmp\n",
      "  Installing build dependencies ... \u001B[?25ldone\n",
      "\u001B[?25h  Checking if build backend supports build_editable ... \u001B[?25ldone\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\n",
      "\u001B[?25hCollecting dsdk[psycopg2,pymssql]@ git+https://github.com/pennsignals/dsdk.git@1.5.6#egg=dsdk\n",
      "  Cloning https://github.com/pennsignals/dsdk.git (to revision 1.5.6) to ./pip-install-ut_whu8b/dsdk_fb8765e8132e436a985c0386117b6bcf\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/pennsignals/dsdk.git /tmp/pip-install-ut_whu8b/dsdk_fb8765e8132e436a985c0386117b6bcf\n",
      "  Running command git checkout -q ffd8a3ebab0488612396640578deb463ce0e8e74\n",
      "  Resolved https://github.com/pennsignals/dsdk.git to commit ffd8a3ebab0488612396640578deb463ce0e8e74\n",
      "  Installing build dependencies ... \u001B[?25ldone\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\n",
      "\u001B[?25hRequirement already satisfied: pip>=22.0.4 in /root/.venv/lib/python3.9/site-packages (from example==0.1.dev0) (22.0.4)\n",
      "Requirement already satisfied: python-dateutil in /root/.venv/lib/python3.9/site-packages (from example==0.1.dev0) (2.8.2)\n",
      "Requirement already satisfied: pandas>=1.3.5 in /root/.venv/lib/python3.9/site-packages (from example==0.1.dev0) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.7.3 in /root/.venv/lib/python3.9/site-packages (from example==0.1.dev0) (1.8.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /root/.venv/lib/python3.9/site-packages (from example==0.1.dev0) (1.1.1)\n",
      "Requirement already satisfied: setuptools>=61.2.0 in /root/.venv/lib/python3.9/site-packages (from example==0.1.dev0) (62.3.2)\n",
      "Requirement already satisfied: setuptools-scm[toml]>=6.4.2 in /root/.venv/lib/python3.9/site-packages (from example==0.1.dev0) (6.4.2)\n",
      "Requirement already satisfied: wheel>=0.37.1 in /root/.venv/lib/python3.9/site-packages (from example==0.1.dev0) (0.37.1)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /root/.venv/lib/python3.9/site-packages (from example==0.1.dev0) (1.22.3)\n",
      "Collecting mypy\n",
      "  Downloading mypy-0.950-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (17.9 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m17.9/17.9 MB\u001B[0m \u001B[31m2.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hCollecting cruft\n",
      "  Downloading cruft-2.10.2-py3-none-any.whl (23 kB)\n",
      "Collecting flake8-logging-format\n",
      "  Downloading flake8-logging-format-0.6.0.tar.gz (5.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\n",
      "\u001B[?25hCollecting flake8-docstrings\n",
      "  Downloading flake8_docstrings-1.6.0-py2.py3-none-any.whl (5.7 kB)\n",
      "Requirement already satisfied: black in /root/.venv/lib/python3.9/site-packages (from example==0.1.dev0) (22.3.0)\n",
      "Collecting pylint\n",
      "  Downloading pylint-2.13.9-py3-none-any.whl (438 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m438.5/438.5 KB\u001B[0m \u001B[31m3.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hCollecting pytest-cov\n",
      "  Downloading pytest_cov-3.0.0-py3-none-any.whl (20 kB)\n",
      "Collecting pytest\n",
      "  Downloading pytest-7.1.2-py3-none-any.whl (297 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m297.0/297.0 KB\u001B[0m \u001B[31m3.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hCollecting pre-commit\n",
      "  Downloading pre_commit-2.19.0-py2.py3-none-any.whl (199 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m199.3/199.3 KB\u001B[0m \u001B[31m2.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hCollecting flake8-sorted-keys\n",
      "  Downloading flake8_sorted_keys-0.2.0-py2.py3-none-any.whl (3.7 kB)\n",
      "Collecting types-python-dateutil\n",
      "  Downloading types_python_dateutil-2.8.16-py3-none-any.whl (7.9 kB)\n",
      "Collecting flake8-commas\n",
      "  Downloading flake8_commas-2.1.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting types-pkg-resources\n",
      "  Downloading types_pkg_resources-0.1.3-py2.py3-none-any.whl (4.8 kB)\n",
      "Collecting astroid\n",
      "  Downloading astroid-2.11.5-py3-none-any.whl (250 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m251.0/251.0 KB\u001B[0m \u001B[31m1.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hCollecting flake8-comprehensions\n",
      "  Downloading flake8_comprehensions-3.10.0-py3-none-any.whl (7.3 kB)\n",
      "Collecting flake8-mutable\n",
      "  Downloading flake8-mutable-1.2.0.tar.gz (3.0 kB)\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\n",
      "\u001B[?25hCollecting coverage[toml]\n",
      "  Downloading coverage-6.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m210.7/210.7 KB\u001B[0m \u001B[31m4.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hCollecting pep8-naming\n",
      "  Downloading pep8_naming-0.12.1-py2.py3-none-any.whl (8.9 kB)\n",
      "Collecting flake8\n",
      "  Downloading flake8-4.0.1-py2.py3-none-any.whl (64 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m64.1/64.1 KB\u001B[0m \u001B[31m3.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting flake8-bugbear\n",
      "  Downloading flake8_bugbear-22.4.25-py3-none-any.whl (19 kB)\n",
      "Collecting types-pyyaml\n",
      "  Downloading types_PyYAML-6.0.7-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/.venv/lib/python3.9/site-packages (from pandas>=1.3.5->example==0.1.dev0) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /root/.venv/lib/python3.9/site-packages (from python-dateutil->example==0.1.dev0) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /root/.venv/lib/python3.9/site-packages (from scikit-learn>=1.0.2->example==0.1.dev0) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /root/.venv/lib/python3.9/site-packages (from scikit-learn>=1.0.2->example==0.1.dev0) (3.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/.venv/lib/python3.9/site-packages (from setuptools-scm[toml]>=6.4.2->example==0.1.dev0) (21.3)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /root/.venv/lib/python3.9/site-packages (from setuptools-scm[toml]>=6.4.2->example==0.1.dev0) (2.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.10 in /root/.venv/lib/python3.9/site-packages (from astroid->example==0.1.dev0) (4.2.0)\n",
      "Collecting wrapt<2,>=1.11\n",
      "  Downloading wrapt-1.14.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m77.8/77.8 KB\u001B[0m \u001B[31m4.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting lazy-object-proxy>=1.4.0\n",
      "  Downloading lazy_object_proxy-1.7.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m61.1/61.1 KB\u001B[0m \u001B[31m3.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: mypy-extensions>=0.4.3 in /root/.venv/lib/python3.9/site-packages (from black->example==0.1.dev0) (0.4.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /root/.venv/lib/python3.9/site-packages (from black->example==0.1.dev0) (8.1.3)\n",
      "Requirement already satisfied: platformdirs>=2 in /root/.venv/lib/python3.9/site-packages (from black->example==0.1.dev0) (2.5.1)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /root/.venv/lib/python3.9/site-packages (from black->example==0.1.dev0) (0.9.0)\n",
      "Collecting typer<0.5.0,>=0.4.0\n",
      "  Downloading typer-0.4.1-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: gitpython<4.0,>=3.0 in /root/.venv/lib/python3.9/site-packages (from cruft->example==0.1.dev0) (3.1.27)\n",
      "Collecting cookiecutter<2.0,>=1.6\n",
      "  Downloading cookiecutter-1.7.3-py2.py3-none-any.whl (34 kB)\n",
      "Collecting cfgenvy@ git+https://github.com/pennsignals/cfgenvy.git@1.3.4#egg=cfgenvy\n",
      "  Cloning https://github.com/pennsignals/cfgenvy.git (to revision 1.3.4) to ./pip-install-ut_whu8b/cfgenvy_46902556655446f1a7d91192ebdf0c2a\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/pennsignals/cfgenvy.git /tmp/pip-install-ut_whu8b/cfgenvy_46902556655446f1a7d91192ebdf0c2a\n",
      "  Running command git checkout -q b148c6f0a4aa5479d6586f622161045858270d80\n",
      "  Resolved https://github.com/pennsignals/cfgenvy.git to commit b148c6f0a4aa5479d6586f622161045858270d80\n",
      "  Installing build dependencies ... \u001B[?25ldone\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\n",
      "\u001B[?25hRequirement already satisfied: requests>=2.26.0 in /root/.venv/lib/python3.9/site-packages (from dsdk[psycopg2,pymssql]@ git+https://github.com/pennsignals/dsdk.git@1.5.6#egg=dsdk->example==0.1.dev0) (2.27.1)\n",
      "Requirement already satisfied: pymssql>=2.2.3 in /root/.venv/lib/python3.9/site-packages (from dsdk[psycopg2,pymssql]@ git+https://github.com/pennsignals/dsdk.git@1.5.6#egg=dsdk->example==0.1.dev0) (2.2.5)\n",
      "Requirement already satisfied: cython>=0.29.21 in /root/.venv/lib/python3.9/site-packages (from dsdk[psycopg2,pymssql]@ git+https://github.com/pennsignals/dsdk.git@1.5.6#egg=dsdk->example==0.1.dev0) (0.29.30)\n",
      "Requirement already satisfied: psycopg2-binary>=2.8.6 in /root/.venv/lib/python3.9/site-packages (from dsdk[psycopg2,pymssql]@ git+https://github.com/pennsignals/dsdk.git@1.5.6#egg=dsdk->example==0.1.dev0) (2.9.3)\n",
      "Collecting mccabe<0.7.0,>=0.6.0\n",
      "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
      "Collecting pycodestyle<2.9.0,>=2.8.0\n",
      "  Downloading pycodestyle-2.8.0-py2.py3-none-any.whl (42 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m42.1/42.1 KB\u001B[0m \u001B[31m3.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting pyflakes<2.5.0,>=2.4.0\n",
      "  Downloading pyflakes-2.4.0-py2.py3-none-any.whl (69 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m69.7/69.7 KB\u001B[0m \u001B[31m4.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: attrs>=19.2.0 in /root/.venv/lib/python3.9/site-packages (from flake8-bugbear->example==0.1.dev0) (21.4.0)\n",
      "Collecting pydocstyle>=2.1\n",
      "  Downloading pydocstyle-6.1.1-py3-none-any.whl (37 kB)\n",
      "Collecting flake8-polyfill<2,>=1.0.2\n",
      "  Downloading flake8_polyfill-1.0.2-py2.py3-none-any.whl (7.3 kB)\n",
      "Collecting nodeenv>=0.11.1\n",
      "  Downloading nodeenv-1.6.0-py2.py3-none-any.whl (21 kB)\n",
      "Collecting identify>=1.0.0\n",
      "  Downloading identify-2.5.1-py2.py3-none-any.whl (98 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m98.6/98.6 KB\u001B[0m \u001B[31m4.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting virtualenv>=20.0.8\n",
      "  Downloading virtualenv-20.14.1-py2.py3-none-any.whl (8.8 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m8.8/8.8 MB\u001B[0m \u001B[31m3.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: pyyaml>=5.1 in /root/.venv/lib/python3.9/site-packages (from pre-commit->example==0.1.dev0) (6.0)\n",
      "Collecting cfgv>=2.0.0\n",
      "  Downloading cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\n",
      "Requirement already satisfied: toml in /root/.venv/lib/python3.9/site-packages (from pre-commit->example==0.1.dev0) (0.10.2)\n",
      "Requirement already satisfied: isort<6,>=4.2.5 in /root/.venv/lib/python3.9/site-packages (from pylint->example==0.1.dev0) (5.10.1)\n",
      "Collecting dill>=0.2\n",
      "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m95.8/95.8 KB\u001B[0m \u001B[31m4.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting iniconfig\n",
      "  Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n",
      "Collecting py>=1.8.2\n",
      "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m98.7/98.7 KB\u001B[0m \u001B[31m4.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting pluggy<2.0,>=0.12\n",
      "  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting jinja2-time>=0.2.0\n",
      "  Downloading jinja2_time-0.2.0-py2.py3-none-any.whl (6.4 kB)\n",
      "Collecting binaryornot>=0.4.4\n",
      "  Downloading binaryornot-0.4.4-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting python-slugify>=4.0.0\n",
      "  Downloading python_slugify-6.1.2-py2.py3-none-any.whl (9.4 kB)\n",
      "Collecting poyo>=0.5.0\n",
      "  Downloading poyo-0.5.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: Jinja2<4.0.0,>=2.7 in /root/.venv/lib/python3.9/site-packages (from cookiecutter<2.0,>=1.6->cruft->example==0.1.dev0) (3.1.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /root/.venv/lib/python3.9/site-packages (from gitpython<4.0,>=3.0->cruft->example==0.1.dev0) (4.0.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /root/.venv/lib/python3.9/site-packages (from packaging>=20.0->setuptools-scm[toml]>=6.4.2->example==0.1.dev0) (3.0.9)\n",
      "Collecting snowballstemmer\n",
      "  Downloading snowballstemmer-2.2.0-py2.py3-none-any.whl (93 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m93.0/93.0 KB\u001B[0m \u001B[31m4.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: idna<4,>=2.5 in /root/.venv/lib/python3.9/site-packages (from requests>=2.26.0->dsdk[psycopg2,pymssql]@ git+https://github.com/pennsignals/dsdk.git@1.5.6#egg=dsdk->example==0.1.dev0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /root/.venv/lib/python3.9/site-packages (from requests>=2.26.0->dsdk[psycopg2,pymssql]@ git+https://github.com/pennsignals/dsdk.git@1.5.6#egg=dsdk->example==0.1.dev0) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/.venv/lib/python3.9/site-packages (from requests>=2.26.0->dsdk[psycopg2,pymssql]@ git+https://github.com/pennsignals/dsdk.git@1.5.6#egg=dsdk->example==0.1.dev0) (2022.5.18.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /root/.venv/lib/python3.9/site-packages (from requests>=2.26.0->dsdk[psycopg2,pymssql]@ git+https://github.com/pennsignals/dsdk.git@1.5.6#egg=dsdk->example==0.1.dev0) (2.0.12)\n",
      "Collecting filelock<4,>=3.2\n",
      "  Downloading filelock-3.7.0-py3-none-any.whl (10 kB)\n",
      "Collecting distlib<1,>=0.3.1\n",
      "  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m461.2/461.2 KB\u001B[0m \u001B[31m4.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hCollecting chardet>=3.0.2\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m178.7/178.7 KB\u001B[0m \u001B[31m5.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: smmap<6,>=3.0.1 in /root/.venv/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython<4.0,>=3.0->cruft->example==0.1.dev0) (3.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/.venv/lib/python3.9/site-packages (from Jinja2<4.0.0,>=2.7->cookiecutter<2.0,>=1.6->cruft->example==0.1.dev0) (2.1.1)\n",
      "Collecting arrow\n",
      "  Downloading arrow-1.2.2-py3-none-any.whl (64 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m64.0/64.0 KB\u001B[0m \u001B[31m4.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m78.2/78.2 KB\u001B[0m \u001B[31m4.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hBuilding wheels for collected packages: flake8-logging-format, flake8-mutable\n",
      "  Building wheel for flake8-logging-format (setup.py) ... \u001B[?25ldone\n",
      "\u001B[?25h  Created wheel for flake8-logging-format: filename=flake8_logging_format-0.6.0-py2.py3-none-any.whl size=5446 sha256=003fcb6554c69ebd293ef6078f12aa39d898ce830e412c4c7220ffe71ebfca46\n",
      "  Stored in directory: /root/.cache/pip/wheels/f3/57/0f/b903222af25203d5fdad588f6afd5d101a0f6b1802c99821e7\n",
      "  Building wheel for flake8-mutable (setup.py) ... \u001B[?25ldone\n",
      "\u001B[?25h  Created wheel for flake8-mutable: filename=flake8_mutable-1.2.0-py3-none-any.whl size=3305 sha256=2a74072f5ca2627ac866380accb4ca6f08828c9de70d4d36fdd684390262af31\n",
      "  Stored in directory: /root/.cache/pip/wheels/ed/63/38/01208ae8de3d32f8ea6cda26e186e7e187bad3d105dd3b4d25\n",
      "Successfully built flake8-logging-format flake8-mutable\n",
      "Installing collected packages: types-pyyaml, types-python-dateutil, types-pkg-resources, text-unidecode, snowballstemmer, nodeenv, mccabe, iniconfig, flake8-logging-format, distlib, wrapt, typer, python-slugify, pyflakes, pydocstyle, pycodestyle, py, poyo, pluggy, mypy, lazy-object-proxy, identify, filelock, dill, coverage, chardet, cfgv, virtualenv, pytest, flake8, binaryornot, astroid, arrow, pytest-cov, pylint, pre-commit, jinja2-time, flake8-sorted-keys, flake8-polyfill, flake8-mutable, flake8-docstrings, flake8-comprehensions, flake8-commas, flake8-bugbear, pep8-naming, cookiecutter, cruft, example\n",
      "  Running setup.py develop for example\n",
      "Successfully installed arrow-1.2.2 astroid-2.11.5 binaryornot-0.4.4 cfgv-3.3.1 chardet-4.0.0 cookiecutter-1.7.3 coverage-6.3.3 cruft-2.10.2 dill-0.3.5.1 distlib-0.3.4 example-0.1.dev0 filelock-3.7.0 flake8-4.0.1 flake8-bugbear-22.4.25 flake8-commas-2.1.0 flake8-comprehensions-3.10.0 flake8-docstrings-1.6.0 flake8-logging-format-0.6.0 flake8-mutable-1.2.0 flake8-polyfill-1.0.2 flake8-sorted-keys-0.2.0 identify-2.5.1 iniconfig-1.1.1 jinja2-time-0.2.0 lazy-object-proxy-1.7.1 mccabe-0.6.1 mypy-0.950 nodeenv-1.6.0 pep8-naming-0.12.1 pluggy-1.0.0 poyo-0.5.0 pre-commit-2.19.0 py-1.11.0 pycodestyle-2.8.0 pydocstyle-6.1.1 pyflakes-2.4.0 pylint-2.13.9 pytest-7.1.2 pytest-cov-3.0.0 python-slugify-6.1.2 snowballstemmer-2.2.0 text-unidecode-1.3 typer-0.4.1 types-pkg-resources-0.1.3 types-python-dateutil-2.8.16 types-pyyaml-6.0.7 virtualenv-20.14.1 wrapt-1.14.1\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install -e \".[all]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c89f2e-1625-47a5-96c1-09cd820e46de",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.1.1 Setup (continued):\n",
    "\n",
    "3. Reload the conda env after each production mode install and once after a development mode install. Use the restart button next to the run and stop buttons in the toolbar.\n",
    "\n",
    "4. Check outdated packages for any unexpected suprises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5a00916-8173-405d-bba1-accdf201dd5e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "122a1de6-5b94-421e-955f-263a1ef9e3cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package      Version  Latest      Type  Editable project location\n",
      "------------ -------- ----------- ----- -------------------------\n",
      "example      0.1.dev0 0.1.0       sdist /tmp/predict/src\n",
      "json5        0.9.5    0.9.8       sdist\n",
      "mccabe       0.6.1    0.7.0       wheel\n",
      "mistune      0.8.4    2.0.2       wheel\n",
      "numexpr      2.8.0    2.8.1       wheel\n",
      "numpy        1.22.3   1.22.4      wheel\n",
      "pip          22.0.4   22.1        wheel\n",
      "platformdirs 2.5.1    2.5.2       wheel\n",
      "psutil       5.9.0    5.9.1       wheel\n",
      "PyQt5        5.15.4   5.15.6      wheel\n",
      "PyQt5-sip    12.9.0   12.10.1     wheel\n",
      "scipy        1.8.0    1.8.1       wheel\n",
      "sip          6.5.1    6.6.1       wheel\n",
      "smmap        3.0.5    5.0.0       wheel\n",
      "soupsieve    2.3.1    2.3.2.post1 wheel\n"
     ]
    }
   ],
   "source": [
    "!pip list --outdated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b20e27-4caf-4575-9e94-b9e655e16c14",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Manage Configuration & Environment\n",
    "\n",
    "### 2.1. Files\n",
    "\n",
    "Because deserializing objects is less error prone than (re-)configuring previously existing python objects, use cfgenvy to load and dump yaml as configuration. Merge environment variable files into yaml configuration during deserialization, and keep your secrets separate and safe.\n",
    "\n",
    "Secrets as well as differences among deployment environments are placed in .env files: `./predict/secrets/`.\n",
    "\n",
    "Configurations are placed in .yaml files: `./predict/local/`.\n",
    "\n",
    "These directories have .gitignore protection from accidental inclusion in version control. See the `./predict/secrets/.gitignore` and `./predict/local/.gitignore` files for file names that *ARE* included in version control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "941def67-9670-40f5-a812-73faf06e5bc7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dsdk import Asset, Mssql, Postgres\n",
    "from cfgenvy import yaml_loads, yaml_dumps, Parser, YamlMapping\n",
    "from typing import Any, Dict, List, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ce0457-3243-455a-b92c-7cbfb0076068",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Some file names and a parser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "212e8af7-bd38-43fa-9783-418747673989",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config_file = \"./predict/local/notebook.example.yaml\"\n",
    "env_file = \"./predict/secrets/notebook.example.env\"\n",
    "\n",
    "parser = Parser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedffd27-b17a-4ce9-98aa-97fe7fa19c11",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Service names are resolved to host ip addresses by docker DNS as listed in docker-compose.override.yaml, and later by consul DNS in production. Use service names when possible instead of ip addresses. Even names for external services external like clarity, and epic can be registered in consul DNS to keep ip addresses out of configuration files.\n",
    "\n",
    "Here the MSSQL_HOST and POSTGRES_HOST are service names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80a9f7dd-9860-4304-94b2-af4631888652",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "envs_str = \"\"\"\n",
    "EPIC_COOKIE=cookie\n",
    "MSSQL_DATABASE=clarity\n",
    "MSSQL_HOST=mssql\n",
    "MSSQL_PASSWORD=password\n",
    "MSSQL_PORT=1433\n",
    "MSSQL_USERNAME=username\n",
    "POSTGRES_DATABASE=test\n",
    "POSTGRES_HOST=postgres\n",
    "POSTGRES_PASSWORD=password\n",
    "POSTGRES_PORT=5432\n",
    "POSTGRES_SCHEMA=test\n",
    "POSTGRES_USERNAME=postgres\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b8886cf-6a55-4003-a9d1-ce39197b194e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(env_file, \"w\", encoding=\"utf-8\") as fout:\n",
    "    fout.write(envs_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f01672cc-6c4b-47e2-b3fe-07bfa6f42bae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cfgs_str = \"\"\"\n",
    "elixhauser:\n",
    "  key1: val1\n",
    "  key2: val2\n",
    "  key3: val3\n",
    "mssql: !mssql\n",
    "  database: ${MSSQL_DATABASE}\n",
    "  host: ${MSSQL_HOST}\n",
    "  password: ${MSSQL_PASSWORD}\n",
    "  port: ${MSSQL_PORT}\n",
    "  schema: test\n",
    "  sql: !asset\n",
    "    path: ./predict/sql/mssql\n",
    "    ext: .sql\n",
    "  username: ${MSSQL_USERNAME}\n",
    "postgres: !postgres\n",
    "  database: ${POSTGRES_DATABASE}\n",
    "  host: ${POSTGRES_HOST}\n",
    "  password: ${POSTGRES_PASSWORD}\n",
    "  port: ${POSTGRES_PORT}\n",
    "  schema: test\n",
    "  sql: !asset\n",
    "    path: ./predict/sql/postgres\n",
    "    ext: .sql\n",
    "  username: ${POSTGRES_USERNAME}\n",
    "stages:\n",
    "- first\n",
    "- second\n",
    "- third\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b156e31-9102-4f17-8d7c-8f3f55330d92",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(config_file, \"w\", encoding=\"utf-8\") as fout:\n",
    "    fout.write(cfgs_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5156c2a0-dac6-4aac-81fa-78d38047c366",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Register classes as yaml types so they may be deserialized as instaces of python classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "722f9425-b04a-483c-9664-399c5f99fafa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(cfg): <class 'dict'>\n",
      "type(cfg['elixhauser']: <class 'dict'>\n",
      "type(cfg['postgres']: <class 'dsdk.postgres.Persistor'>\n",
      "type(cfg['postgres'].sql: <class 'dsdk.asset.Asset'>\n",
      "type(cfg['stages']): <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "Mssql.as_yaml_type()\n",
    "Postgres.as_yaml_type()\n",
    "\n",
    "cfg = parser.load(\n",
    "    config_file=config_file,\n",
    "    env_file=env_file,\n",
    ")\n",
    "\n",
    "print(f\"type(cfg): {type(cfg)}\")\n",
    "print(f\"type(cfg['elixhauser']: {type(cfg['elixhauser'])}\")\n",
    "print(f\"type(cfg['postgres']: {type(cfg['postgres'])}\")\n",
    "print(f\"type(cfg['postgres'].sql: {type(cfg['postgres'].sql)}\")\n",
    "print(f\"type(cfg['stages']): {type(cfg['stages'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53d8a71-5133-44bf-a103-dfd23b68b0b0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Create and register a class to provide better validation for confguration and by ensuring that the configuration file is not mismatched, use explicit yaml `!<type>` and a clss. Unlike a python dictionary, unexpected or missing keywords will raise early exceptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acfd8b1c-d259-4213-b9f2-256297bb8ff9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(config_file, \"w\", encoding=\"utf-8\") as fout:\n",
    "    fout.write(\"!cfg\" + cfgs_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87ee8d93-75bb-4c10-ad21-75a672c34d51",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Cfg(YamlMapping):\n",
    "\n",
    "    YAML = '!cfg'\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        elixhauser: Dict[str, str],\n",
    "        mssql: Mssql,\n",
    "        postgres: Postgres,\n",
    "        stages: List,\n",
    "    ):\n",
    "        self.elixhauser = elixhauser\n",
    "        self.mssql = mssql\n",
    "        self.postgres = postgres\n",
    "        self.stages = stages\n",
    "    \n",
    "    def as_yaml(self) -> Dict[str, Any]:\n",
    "        \"\"\"As yaml.\"\"\"\n",
    "        return {\n",
    "            \"elixhauser\": self.elixhauser,\n",
    "            \"mssql\": self.mssql,\n",
    "            \"postgres\": self.postgres,\n",
    "            \"stages\": self.stages,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20ba1b4e-83e4-4438-a825-5e2a10f29ea0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(cfg): <class '__main__.Cfg'>\n",
      "type(cfg.elixhauser): <class 'dict'>\n",
      "type(cfg.postgres): <class 'dsdk.postgres.Persistor'>\n",
      "type(cfg.postgres.sql): <class 'dsdk.asset.Asset'>\n",
      "type(cfg.stages): <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "Cfg.as_yaml_type()\n",
    "\n",
    "cfg = parser.load(\n",
    "    config_file=config_file,\n",
    "    env_file=env_file,\n",
    ")\n",
    "\n",
    "print(f\"type(cfg): {type(cfg)}\")\n",
    "print(f\"type(cfg.elixhauser): {type(cfg.elixhauser)}\")\n",
    "print(f\"type(cfg.postgres): {type(cfg.postgres)}\")\n",
    "print(f\"type(cfg.postgres.sql): {type(cfg.postgres.sql)}\")\n",
    "print(f\"type(cfg.stages): {type(cfg.stages)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d232f7ed-66aa-4088-88a3-92824bdcf0f3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "postgres = cfg.postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13403b07-2b21-4a5a-9f9b-4ba2313cd98a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Debug the final merged configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57cb790a-42a9-49c1-a29b-36534106adc5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!postgres\n",
      "database: test\n",
      "host: postgres\n",
      "password: password\n",
      "port: '5432'\n",
      "schema: test\n",
      "sql: !asset\n",
      "  ext: .sql\n",
      "  path: ./predict/sql/postgres\n",
      "username: postgres\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(yaml_dumps(postgres))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883cdb6f-32ae-4d10-8ec2-10af7512f8af",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Check Database Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4af65f71-0588-40cb-89bb-0cd7710ef5d6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Very database, much wow!',)\n"
     ]
    }
   ],
   "source": [
    "with postgres.rollback() as cursor:\n",
    "    cursor.execute(\"\"\"select 'Very database, much wow!' as doge\"\"\")\n",
    "    rows = cursor.fetchall()\n",
    "    print(rows[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c1cf36",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. Manage SQL & Other Text Assets\n",
    "\n",
    "Assets loads text files from disk. Unlike SQL embedded in python strings, SQL syntax highlighting may be available in text editor. The python placeholders expected by psycopg2 and pymssql will still be marked as errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7a7bc2f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select\n",
      "    score\n",
      "from\n",
      "    predictions\n",
      "where\n",
      "    run_id = %(run_id)s\n",
      "order by\n",
      "    id desc;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(postgres.sql.predictions.gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0faa1ce-1357-4a3e-bdd2-d9298fc153a8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 5. Rethink SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e91d456b-5405-4d64-8ddd-11c40a03a3f9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "keys = {\n",
    "    \"cohort\": ('00001', '00002', '00003'),\n",
    "    \"conditions\" : ('sleepy', 'happy', 'grumpy'),\n",
    "}\n",
    "\n",
    "parameters = {\n",
    "    \"dry_run\": 0,\n",
    "    \"cohort_begin\": '2021-05-05',\n",
    "    \"cohort_end\": '2021-05-06',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f508827",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 5.1. Prefer `with` over `in (?, ...)`:\n",
    "\n",
    "Avoid `in` for more than a few elements:\n",
    "\n",
    "`select * from patients where id in ('00001', '00002', '00003', ...);`\n",
    "\n",
    "Unfortunately, the execution plan renders `in` similar to multiple `or`:\n",
    "\n",
    "`select * from patients where id = '00001' or id = '00002' or id = '00003' ...;`\n",
    "\n",
    "The performance is terrible. The database has limits on the number of elements that may be included using `in (?, ...)`. Fundamentally, the database does not treat `in` like a table with a single column, in part because the column data type is not known. Client languages like python typically only have data types that approximately match the database's data types. For example the pymssql driver passes all python strings to mssql as `nvarchar` literals ('n' is not a typo). Each element is coherced to the most permissive data type during comparison. This implicit, permissive casting and cohersion prevents indices from being used.\n",
    "\n",
    "Use `with` instead and `cast` the column to the appropriate data type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748747ae",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5.1.1. Example:\n",
    "\n",
    "An easy example in templated sql for python and dsdk looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9193176b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id\n",
       "0  00001\n",
       "1  00002\n",
       "2  00003"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_5_1_1 = '''\n",
    "with cohort as (\n",
    "    select cast(null as varchar(8)) as id -- data type is on the cohort.id column, not just this first row\n",
    "    {cohort}\n",
    ")\n",
    "select\n",
    "    id\n",
    "from\n",
    "    cohort\n",
    "where\n",
    "    id is not null;'''\n",
    "\n",
    "with postgres.rollback() as cur:\n",
    "    df = postgres.df_from_query(cur, query_5_1_1, keys=keys, parameters=parameters)\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae0035b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5.1.2. Example:\n",
    "\n",
    "A more useful example using dsdk looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68b1c73d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort_begin</th>\n",
       "      <th>cohort_end</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-05 00:00:00+00:00</td>\n",
       "      <td>2021-05-06 00:00:00+00:00</td>\n",
       "      <td>00001</td>\n",
       "      <td>sleepy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-05 00:00:00+00:00</td>\n",
       "      <td>2021-05-06 00:00:00+00:00</td>\n",
       "      <td>00001</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-05 00:00:00+00:00</td>\n",
       "      <td>2021-05-06 00:00:00+00:00</td>\n",
       "      <td>00001</td>\n",
       "      <td>grumpy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-05 00:00:00+00:00</td>\n",
       "      <td>2021-05-06 00:00:00+00:00</td>\n",
       "      <td>00002</td>\n",
       "      <td>sleepy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-05 00:00:00+00:00</td>\n",
       "      <td>2021-05-06 00:00:00+00:00</td>\n",
       "      <td>00002</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-05-05 00:00:00+00:00</td>\n",
       "      <td>2021-05-06 00:00:00+00:00</td>\n",
       "      <td>00002</td>\n",
       "      <td>grumpy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-05-05 00:00:00+00:00</td>\n",
       "      <td>2021-05-06 00:00:00+00:00</td>\n",
       "      <td>00003</td>\n",
       "      <td>sleepy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-05-05 00:00:00+00:00</td>\n",
       "      <td>2021-05-06 00:00:00+00:00</td>\n",
       "      <td>00003</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-05-05 00:00:00+00:00</td>\n",
       "      <td>2021-05-06 00:00:00+00:00</td>\n",
       "      <td>00003</td>\n",
       "      <td>grumpy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cohort_begin                cohort_end     id    name\n",
       "0 2021-05-05 00:00:00+00:00 2021-05-06 00:00:00+00:00  00001  sleepy\n",
       "1 2021-05-05 00:00:00+00:00 2021-05-06 00:00:00+00:00  00001   happy\n",
       "2 2021-05-05 00:00:00+00:00 2021-05-06 00:00:00+00:00  00001  grumpy\n",
       "3 2021-05-05 00:00:00+00:00 2021-05-06 00:00:00+00:00  00002  sleepy\n",
       "4 2021-05-05 00:00:00+00:00 2021-05-06 00:00:00+00:00  00002   happy\n",
       "5 2021-05-05 00:00:00+00:00 2021-05-06 00:00:00+00:00  00002  grumpy\n",
       "6 2021-05-05 00:00:00+00:00 2021-05-06 00:00:00+00:00  00003  sleepy\n",
       "7 2021-05-05 00:00:00+00:00 2021-05-06 00:00:00+00:00  00003   happy\n",
       "8 2021-05-05 00:00:00+00:00 2021-05-06 00:00:00+00:00  00003  grumpy"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_5_1_2 = '''\n",
    "with args as (\n",
    "    select\n",
    "        cast(%(cohort_begin)s as timestamptz) as cohort_begin,\n",
    "        cast(%(cohort_end)s as timestamptz) as cohort_end\n",
    "), cohort as (\n",
    "    select cast(null as varchar(8)) as id\n",
    "    {cohort}\n",
    "), conditions as (\n",
    "    select cast(null as varchar(16)) as name\n",
    "    {conditions}\n",
    ")\n",
    "select\n",
    "    cohort_begin,\n",
    "    cohort_end,\n",
    "    id,\n",
    "    name\n",
    "from\n",
    "    args\n",
    "    join cohort\n",
    "        on id is not null\n",
    "    join conditions\n",
    "        on name is not null;\n",
    "'''\n",
    "\n",
    "with postgres.rollback() as cur:\n",
    "    df = postgres.df_from_query(cur, query_5_1_2, keys=keys, parameters=parameters)\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1152c19",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5.1.3. Example\n",
    "\n",
    "Implementation of dsdk for df_from_query_by_keys uses `union all select` implementation. This formulation avoids item limits as well as comma counting of `insert (...) values (...), ...`. Unlike `in` and `insert (...) values (...), ...` it also results in perfectly valid sql even when the cohort or conditions lists empty, because the empty lists render as code while retaining the column data type(s) using the \"null row\".\n",
    "\n",
    "Unwind the sequences and replace the placeholders in pgadmin, DBeaver, Data Grip, and Microsort Sql Server Management Studio to test and explain your queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67d4bb3e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort_begin</th>\n",
       "      <th>cohort_end</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-05 00:00:00+00:00</td>\n",
       "      <td>2021-05-06 00:00:00+00:00</td>\n",
       "      <td>00001</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-05 00:00:00+00:00</td>\n",
       "      <td>2021-05-06 00:00:00+00:00</td>\n",
       "      <td>00001</td>\n",
       "      <td>sleepy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-05 00:00:00+00:00</td>\n",
       "      <td>2021-05-06 00:00:00+00:00</td>\n",
       "      <td>00001</td>\n",
       "      <td>grumpy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-05 00:00:00+00:00</td>\n",
       "      <td>2021-05-06 00:00:00+00:00</td>\n",
       "      <td>00002</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-05 00:00:00+00:00</td>\n",
       "      <td>2021-05-06 00:00:00+00:00</td>\n",
       "      <td>00002</td>\n",
       "      <td>sleepy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-05-05 00:00:00+00:00</td>\n",
       "      <td>2021-05-06 00:00:00+00:00</td>\n",
       "      <td>00002</td>\n",
       "      <td>grumpy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-05-05 00:00:00+00:00</td>\n",
       "      <td>2021-05-06 00:00:00+00:00</td>\n",
       "      <td>00003</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-05-05 00:00:00+00:00</td>\n",
       "      <td>2021-05-06 00:00:00+00:00</td>\n",
       "      <td>00003</td>\n",
       "      <td>sleepy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-05-05 00:00:00+00:00</td>\n",
       "      <td>2021-05-06 00:00:00+00:00</td>\n",
       "      <td>00003</td>\n",
       "      <td>grumpy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cohort_begin                cohort_end     id    name\n",
       "0 2021-05-05 00:00:00+00:00 2021-05-06 00:00:00+00:00  00001   happy\n",
       "1 2021-05-05 00:00:00+00:00 2021-05-06 00:00:00+00:00  00001  sleepy\n",
       "2 2021-05-05 00:00:00+00:00 2021-05-06 00:00:00+00:00  00001  grumpy\n",
       "3 2021-05-05 00:00:00+00:00 2021-05-06 00:00:00+00:00  00002   happy\n",
       "4 2021-05-05 00:00:00+00:00 2021-05-06 00:00:00+00:00  00002  sleepy\n",
       "5 2021-05-05 00:00:00+00:00 2021-05-06 00:00:00+00:00  00002  grumpy\n",
       "6 2021-05-05 00:00:00+00:00 2021-05-06 00:00:00+00:00  00003   happy\n",
       "7 2021-05-05 00:00:00+00:00 2021-05-06 00:00:00+00:00  00003  sleepy\n",
       "8 2021-05-05 00:00:00+00:00 2021-05-06 00:00:00+00:00  00003  grumpy"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_5_1_3 = '''\n",
    "with args as (\n",
    "    select\n",
    "        cast('2021-05-05' as timestamptz) as cohort_begin,\n",
    "        cast('2021-05-06' as timestamptz) as cohort_end\n",
    "), cohort as (\n",
    "    select cast(null as varchar) as id\n",
    "    union all select '00001'\n",
    "    union all select '00002'\n",
    "    union all select '00003'\n",
    "), conditions as (\n",
    "    select cast(null as varchar) as name\n",
    "    union all select 'happy'\n",
    "    union all select 'sleepy'\n",
    "    union all select 'grumpy'\n",
    ")\n",
    "select\n",
    "    cohort_begin,\n",
    "    cohort_end,\n",
    "    id,\n",
    "    name\n",
    "from\n",
    "    args\n",
    "    join cohort\n",
    "        on id is not null\n",
    "    join conditions\n",
    "        on name is not null;'''\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "with postgres.rollback() as cur:\n",
    "    cur.execute(query_5_1_3)\n",
    "    rows = cur.fetchall()\n",
    "    df = DataFrame(rows)\n",
    "    columns = (each[0] for each in cur.description)\n",
    "    df.columns = columns\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561cec34-f4f5-4c93-a320-50c97a2fed12",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 5.2 Use dry run to fail early\n",
    "\n",
    "Make the database do more work for you. This includes validating some syntax and all permission on the service accounts BEFORE passing actual useful data to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e880100f-f0e7-44f4-b4b9-d367e4209ed0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "query_5_2 = '''\n",
    "with vars as (\n",
    "    select\n",
    "        cast(coalesce(%(dry_run)s, 1) as int) as dry_run,\n",
    "        cast(%(cohort_begin)s as timestamptz) as cohort_begin,\n",
    "        cast(%(cohort_end)s as timestamptz) as cohort_end\n",
    "), cohort as (\n",
    "    select cast(null as varchar) as id\n",
    "    {cohort}\n",
    ")\n",
    "select\n",
    "    no_such_table.*\n",
    "from\n",
    "    vars as v\n",
    "    join cohort as c\n",
    "        on v.dry_run = 0\n",
    "        and c.id is not null;'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9ca12f2-278a-41b6-b6ad-209d3b26de78",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "UndefinedTable",
     "evalue": "missing FROM-clause entry for table \"no_such_table\"\nLINE 12:     no_such_table.*\n             ^\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUndefinedTable\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [23]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mpostgres\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdry_run_query\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery_5_2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.venv/lib/python3.9/site-packages/dsdk/persistor.py:218\u001B[0m, in \u001B[0;36mAbstractPersistor.dry_run_query\u001B[0;34m(self, query, parameters)\u001B[0m\n\u001B[1;32m    216\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m NamedTemporaryFile(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m, delete\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, suffix\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.sql\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m fout:\n\u001B[1;32m    217\u001B[0m     fout\u001B[38;5;241m.\u001B[39mwrite(rendered)\n\u001B[0;32m--> 218\u001B[0m     \u001B[43mcur\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrendered\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mUndefinedTable\u001B[0m: missing FROM-clause entry for table \"no_such_table\"\nLINE 12:     no_such_table.*\n             ^\n"
     ]
    }
   ],
   "source": [
    "postgres.dry_run_query(query_5_2, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441ff7ac-d95a-42d7-aad8-e14b6f58e0a8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Persistors can dry run all sql queries in an asset if all parameters are provided. All queries must be written to select, insert, update or delete no data when dry_run is 1, but must do by producing empty data sets for insert, update, and delete instead of exiting early.\n",
    "\n",
    "Typically, this means using a `with` clause to build a data set for insert, update or delete and performing a join on `dry_run = 0` that knocks out all rows from the data manipulation operators.\n",
    "\n",
    "More examples to come, and all queries in the postgres persistor asset must be revised for dry_run compatibility.\n",
    "\n",
    "More examples to come on when to add unused tables to aquire indices.\n",
    "\n",
    "More examples to come on sql performance profiling and explain.\n",
    "\n",
    "More example on when using temp tables may be an advantage, and the impact on readability, maintainability, and testing.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.venv] *",
   "language": "python",
   "name": "conda-env-.venv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
